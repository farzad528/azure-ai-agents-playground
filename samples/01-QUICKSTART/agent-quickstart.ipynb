{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSISTANT: In Azure AI Search (AZS), \"BQ\" stands for \"Binary Quantization.\" This method compresses high-dimensional vectors by representing each component as a single bit, either 0 or 1. It significantly reduces the memory footprint and accelerates vector comparison operations, which are essential for search and retrieval tasks【3:1†source】. \n",
      "\n",
      "Additionally, Binary Quantization is particularly effective for embeddings that are centered around zero and for those with dimensions greater than 1024【3:1†source】【3:2†source】.\n",
      "USER: BQ means what in AZS?\n"
     ]
    }
   ],
   "source": [
    "from azure.identity import AzureCliCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import AzureAISearchTool\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# CONNECTION_STRING = \"<HostName>; <AzureSubscriptionId>; <ResourceGroup>; <HubName>\"\n",
    "CONNECTION_STRING=os.getenv(\"AZURE_CONNECTION_STRING\")\n",
    "SEARCH_CONNECTION_NAME = os.getenv(\"AI_SEARCH_CONNECTION_NAME\") # Your search connection name\n",
    "SEARCH_INDEX_NAME = os.getenv(\"AI_SEARCH_INDEX_NAME\") # Your search index name\n",
    "\n",
    "client = AIProjectClient.from_connection_string(\n",
    "credential=AzureCliCredential(),\n",
    "conn_str=CONNECTION_STRING,\n",
    ")\n",
    "\n",
    "conn_id = next(c.id for c in client.connections.list() if c.name == SEARCH_CONNECTION_NAME)\n",
    "\n",
    "search_tool = AzureAISearchTool(\n",
    "    index_connection_id=conn_id,\n",
    "    index_name=SEARCH_INDEX_NAME\n",
    ")\n",
    "\n",
    "agent = client.agents.create_agent(\n",
    "    model=\"gpt-4o-mini\", # Model Deployment Name\n",
    "    name=\"my-assistant\",\n",
    "    instructions=\"You are a helpful assistant that answers questions using Azure AI Search docs\",\n",
    "    tools=search_tool.definitions,\n",
    "    tool_resources=search_tool.resources,\n",
    ")\n",
    "\n",
    "thread = client.agents.create_thread()\n",
    "\n",
    "client.agents.create_message(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"BQ means what in AZS?\",\n",
    ")\n",
    "\n",
    "client.agents.create_and_process_run(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=agent.id,\n",
    ")\n",
    "\n",
    "messages = client.agents.list_messages(thread_id=thread.id)\n",
    "for message in messages['data']:\n",
    "    role = message['role'].upper()\n",
    "    content = \"\"\n",
    "    for content_item in message.get(\"content\", []):\n",
    "        content = content_item.get(\"text\", {}).get(\"value\", \"\")\n",
    "    print(f\"{role}: {content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Agents SDK Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response:\n",
      "To use vector search in Azure AI Search, you can follow these key points:\n",
      "\n",
      "1. **Vector Storage**: Azure AI Search supports vector storage at the field level, allowing you to combine vector and non-vector fields in the same search index. You can create a vector store using the Create Index REST API or Azure SDK methods.\n",
      "\n",
      "2. **Schema Design**: Design your schema based on your use case and intended vector retrieval pattern. Ensure to estimate index size and check service capacity.\n",
      "\n",
      "3. **Hybrid Search**: Azure AI Search allows for hybrid scenarios where vector and keyword searches run in parallel, returning a unified result set. This often yields better results than using either method alone.\n",
      "\n",
      "4. **Querying**: To perform a vector search, the query itself must be a vector. You can convert user input into a vector using an embedding library or API. Azure AI Search supports querying multiple vector fields and setting vector weights.\n",
      "\n",
      "5. **Integration**: Vector search is available through various interfaces including the Azure portal, REST APIs, and SDKs for .NET, Python, and JavaScript.\n",
      "\n",
      "6. **Considerations**: Ensure that your Azure search service is capable of supporting vector workloads. Some older services may not support this feature, and you may need to create a new search service.\n",
      "\n",
      "For more detailed guidance, you can refer to the following resources:\n",
      "- [Azure AI Search Vector Search Documentation](https://learn.microsoft.com/en-us/azure/search/search-vector-search)\n",
      "- [Azure Search Vector Samples on GitHub](https://github.com/Azure/azure-search-vector-samples)\n",
      "\n",
      "These resources provide comprehensive information on how to implement and utilize vector search effectively in your applications.\n"
     ]
    }
   ],
   "source": [
    "# Azure AI Search + OpenAI Agents SDK Integration\n",
    "# pip install azure-search-documents openai \"openai-agents>=0.3\" python-dotenv\n",
    "\n",
    "import os\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel\n",
    "from dotenv import load_dotenv\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "from openai import AsyncAzureOpenAI\n",
    "from agents import (\n",
    "    Agent, function_tool, Runner, OpenAIChatCompletionsModel,\n",
    "    set_default_openai_client, set_tracing_disabled, ModelSettings\n",
    ")\n",
    "\n",
    "# Setup for notebooks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize clients\n",
    "search_client = SearchClient(\n",
    "    os.environ.get(\"AZURE_SEARCH_SERVICE_ENDPOINT\"),\n",
    "    \"your index-name\",\n",
    "    AzureKeyCredential(os.environ.get(\"AZURE_SEARCH_ADMIN_KEY\"))\n",
    ")\n",
    "\n",
    "openai_client = AsyncAzureOpenAI(\n",
    "    azure_endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\", \"2024-10-21\"),\n",
    "    azure_deployment=os.environ.get(\"AZURE_OPENAI_CHAT_COMPLETION_DEPLOYED_MODEL_NAME\")\n",
    ")\n",
    "\n",
    "# Configure SDK\n",
    "set_default_openai_client(openai_client)\n",
    "set_tracing_disabled(True)\n",
    "\n",
    "# Define search tool\n",
    "class SearchParams(BaseModel):\n",
    "    query: str\n",
    "    top: Optional[int] = 5\n",
    "\n",
    "@function_tool\n",
    "def search_azure_docs(params: SearchParams) -> List[dict]:\n",
    "    \"\"\"Search Azure AI Search documentation.\"\"\"\n",
    "    vector_query = VectorizableTextQuery(\n",
    "        text=params.query,\n",
    "        k_nearest_neighbors=params.top,\n",
    "        fields=\"text_vector\"\n",
    "    )\n",
    "    \n",
    "    results = search_client.search(\n",
    "        search_text=params.query,\n",
    "        vector_queries=[vector_query],\n",
    "        select=[\"chunk_id\", \"chunk\", \"title\"],\n",
    "        top=params.top\n",
    "    )\n",
    "    \n",
    "    return [{\n",
    "        \"content\": r.get(\"chunk\", \"\"),\n",
    "        \"title\": r.get(\"title\", \"\"),\n",
    "        \"id\": r.get(\"chunk_id\", \"\")\n",
    "    } for r in results]\n",
    "\n",
    "# Create agent\n",
    "agent = Agent(\n",
    "    name=\"Azure AI Search Expert\",\n",
    "    instructions=\"\"\"You are an Azure AI Search expert. Use 'search_azure_docs' tool \n",
    "    to find documentation.\"\"\",\n",
    "    tools=[search_azure_docs],\n",
    "    model=OpenAIChatCompletionsModel(\n",
    "        model=os.environ.get(\"AZURE_OPENAI_CHAT_COMPLETION_DEPLOYED_MODEL_NAME\"),\n",
    "        openai_client=openai_client\n",
    "    ),\n",
    "    model_settings=ModelSettings(temperature=0.3)\n",
    ")\n",
    "\n",
    "# Run agent\n",
    "query = \"How can I use vector search in Azure AI Search?\"\n",
    "result = Runner.run_sync(agent, query)\n",
    "print(f\"\\nResponse:\\n{result.final_output}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
